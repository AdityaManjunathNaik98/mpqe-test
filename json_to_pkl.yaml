name: JSON to PKL Converter
description: Converts JSON graph data to pickle format with train/val/test splits and negative sampling
inputs:
  - name: input_json_file
    type: String
    description: Path to the input JSON file containing graph data
outputs:
  - name: output_pkl_file
    type: Dataset
    description: Output pickle file containing processed graph data with splits
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        set -e
        python3 -m pip install --quiet pickle5
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import json
        import pickle
        import random
        import os
        import argparse
        from itertools import combinations
        from collections import defaultdict


        def convert_json_to_tuples(json_data):
            """
            Convert JSON data with Neo4j graph structure to tuple format.
            Filters out items with underscore characters in labels or relationship types.
            
            Args:
                json_data: List of dictionaries containing 'n', 'r', 'm' keys
                
            Returns:
                List of tuples in the format:
                [(('1-chain', (id, (start_label, relationship, end_label), end_id)), None, None), ...]
            """
            result = []
            
            for item in json_data:
                # Extract node and relationship information
                start_node = item.get('n', {})
                relationship = item.get('r', {})
                end_node = item.get('m', {})
                
                # Get start node info
                start_id = start_node.get('identity', 0)
                start_labels = start_node.get('labels', [])
                start_label = start_labels[0].lower() if start_labels else 'unknown'
                
                # Get relationship info
                rel_type = relationship.get('type', '')
                rel_id = relationship.get('identity', 0)
                
                # Get end node info
                end_id = end_node.get('identity', 0)
                end_labels = end_node.get('labels', [])
                end_label = end_labels[0].lower() if end_labels else 'unknown'
                
                # Filter out items with underscores in labels or relationship type
                if ('_' in str(start_label) or 
                    '_' in str(end_label) or 
                    '_' in str(rel_type)):
                    continue
                
                # Create the tuple structure
                tuple_item = (
                    ('1-chain', (rel_id, (start_label, rel_type, end_label), end_id)),
                    None,
                    None
                )
                
                result.append(tuple_item)
            
            return result


        def process_json_file(input_file):
            """
            Process a JSON file and convert it to tuple format.
            Returns the tuples result.
            """
            try:
                with open(input_file, 'r', encoding='utf-8-sig') as f:
                    json_data = json.load(f)
                
                # Convert to tuples
                tuples_result = convert_json_to_tuples(json_data)
                return tuples_result
                 
            except FileNotFoundError:
                print(f"Error: File '{input_file}' not found.")
                return []
            except json.JSONDecodeError:
                print("Error: Invalid JSON format.")
                return []
            except Exception as e:
                print(f"Error: {e}")
                return []


        def split_data(data, train_ratio=0.6, val_ratio=0.20, test_ratio=0.20):
            """Split data into train, validation, and test sets."""
            random.shuffle(data)
            n = len(data)
            train_end = int(n * train_ratio)
            val_end = int(n * (train_ratio + val_ratio))
            
            train_data = data[:train_end]
            val_data = data[train_end:val_end]
            test_data = data[val_end:]
            
            return train_data, val_data, test_data


        def build_entity_pools(tuples):
            """Build pools of entities organized by type for negative sampling."""
            entity_pools = defaultdict(set)
            
            for tuple_item in tuples:
                rel_id = tuple_item[0][1][0]
                start_label = tuple_item[0][1][1][0]
                end_label = tuple_item[0][1][1][2]
                end_id = tuple_item[0][1][2]
                
                # Add entities to their respective type pools
                entity_pools[start_label].add(rel_id)
                entity_pools[end_label].add(end_id)
            
            # Convert sets to lists for random sampling
            return {entity_type: list(entities) for entity_type, entities in entity_pools.items()}


        def generate_negative_samples(positive_tuple, entity_pools, num_negatives=1):
            """Generate negative samples for a positive tuple."""
            rel_id = positive_tuple[0][1][0]
            start_label = positive_tuple[0][1][1][0]
            rel_type = positive_tuple[0][1][1][1]
            end_label = positive_tuple[0][1][1][2]
            end_id = positive_tuple[0][1][2]
            
            negatives = []
            
            # Get entities of the target type for negative sampling
            if end_label in entity_pools:
                target_entities = entity_pools[end_label]
                # Remove the correct answer from potential negatives
                available_negatives = [e for e in target_entities if e != end_id]
                
                if available_negatives:
                    # Sample negative entities
                    sample_size = min(num_negatives, len(available_negatives))
                    negatives = random.sample(available_negatives, sample_size)
            
            return negatives


        def add_negatives_to_tuples(tuples, entity_pools, num_negatives=1):
            """Add negative samples to existing tuples."""
            updated_tuples = []
            
            for tuple_item in tuples:
                # Generate negative samples
                negatives = generate_negative_samples(tuple_item, entity_pools, num_negatives)
                
                # Create updated tuple with negatives and None as third element (matching original format)
                updated_tuple = (
                    tuple_item[0],  # Keep the positive query structure
                    negatives if negatives else [],  # Add negative samples (empty list if none generated)
                    None            # Keep as None to match original dataset format
                )
                
                updated_tuples.append(updated_tuple)
            
            return updated_tuples


        def convert_to_query_format(tuples):
            """Convert tuples to Query serialization format."""
            query_format_tuples = []
            
            for tuple_item in tuples:
                if tuple_item[0][0] == '1-chain':
                    # For 1-chain: (query_type, (rel_id, (start_type, rel_type, end_type), end_id))
                    query_graph = (
                        tuple_item[0][0],  # '1-chain'
                        tuple_item[0][1]   # The relationship tuple
                    )
                else:
                    # This is already in the right format from complex query generation
                    query_graph = tuple_item[:-2]  # Everything except negatives and None
                
                neg_samples = tuple_item[-2] if tuple_item[-2] else []  # Negative samples
                hard_neg_samples = neg_samples  # Use same negatives as hard negatives (OPTION 1 FIX)
                
                # Create the serialized format: (query_graph, neg_samples, hard_neg_samples)
                serialized_query = (query_graph, neg_samples, hard_neg_samples)
                query_format_tuples.append(serialized_query)
            
            return query_format_tuples


        def convert_complex_queries_to_query_format(query_tuples):
            """Convert complex query tuples to Query serialization format."""
            query_format_tuples = []
            
            for query_tuple in query_tuples:
                # Extract components
                query_type = query_tuple[0]
                
                if query_type in ['2-chain', '2-inter']:
                    # Format: ('2-chain', rel1, rel2, [negatives], None)
                    query_graph = (query_type, query_tuple[1], query_tuple[2])
                    neg_samples = query_tuple[3] if query_tuple[3] else []
                elif query_type in ['3-chain', '3-inter']:
                    # Format: ('3-chain', rel1, rel2, rel3, [negatives], None) 
                    query_graph = (query_type, query_tuple[1], query_tuple[2], query_tuple[3])
                    neg_samples = query_tuple[4] if query_tuple[4] else []
                else:
                    # Default handling
                    query_graph = query_tuple[:-2]
                    neg_samples = query_tuple[-2] if query_tuple[-2] else []
                
                hard_neg_samples = neg_samples  # Use same negatives as hard negatives (OPTION 1 FIX)
                
                # Create the serialized format: (query_graph, neg_samples, hard_neg_samples)
                serialized_query = (query_graph, neg_samples, hard_neg_samples)
                query_format_tuples.append(serialized_query)
            
            return query_format_tuples


        def add_negatives_to_complex_queries(query_tuples, entity_pools, num_negatives=1):
            """Add negative samples to complex query tuples (2-chain, 3-chain, etc.)."""
            updated_queries = []
            
            for query_tuple in query_tuples:
                query_type = query_tuple[0]  # e.g., '2-chain', '3-chain', etc.
                
                # For complex queries, we need to identify what the target should be
                # This depends on the query structure
                if query_type == '2-chain':
                    # For 2-chain, the target is the end of the chain
                    target_id = query_tuple[2][2]  # End of second relationship
                    target_type = query_tuple[2][1][2]  # Target type of second relationship
                elif query_type == '2-inter':
                    # For 2-inter, we can generate negatives for either branch
                    # Let's use the first branch's target
                    target_id = query_tuple[1][2]
                    target_type = query_tuple[1][1][2]
                elif query_type == '3-chain':
                    # For 3-chain, target is end of the chain
                    target_id = query_tuple[3][2]
                    target_type = query_tuple[3][1][2]
                elif query_type == '3-inter':
                    # For 3-inter, use first branch's target
                    target_id = query_tuple[1][2]
                    target_type = query_tuple[1][1][2]
                else:
                    # Default case
                    target_id = None
                    target_type = 'resource'  # Fallback
                
                # Generate negatives
                negatives = []
                if target_type in entity_pools and target_id is not None:
                    available_negatives = [e for e in entity_pools[target_type] if e != target_id]
                    if available_negatives:
                        sample_size = min(num_negatives, len(available_negatives))
                        negatives = random.sample(available_negatives, sample_size)
                
                # Create updated query tuple with correct format
                if query_type in ['2-chain', '2-inter']:
                    # Format: (query_type, rel1, rel2, [negatives], None)
                    updated_query = (
                        query_tuple[0],  # Query type ('2-chain' or '2-inter')
                        query_tuple[1],  # First relationship
                        query_tuple[2],  # Second relationship  
                        negatives,       # Negative samples
                        None             # Final None
                    )
                elif query_type in ['3-chain', '3-inter']:
                    # Format: (query_type, rel1, rel2, rel3, [negatives], None)
                    updated_query = (
                        query_tuple[0],  # Query type ('3-chain' or '3-inter')
                        query_tuple[1],  # First relationship
                        query_tuple[2],  # Second relationship  
                        query_tuple[3],  # Third relationship
                        negatives,       # Negative samples
                        None             # Final None
                    )
                else:
                    # Handle other formats - keep original structure but add negatives
                    updated_query = query_tuple[:-1] + (negatives, None)
                
                updated_queries.append(updated_query)
            
            return updated_queries


        def create_graph_data_structure(tuples):
            """
            Create graph data structure similar to the example provided.
            Returns three dictionaries: relations, triples, and entity_type_mapping.
            """
            # Initialize data structures
            relations = defaultdict(list)  # entity_type -> [(connected_type, relation), ...]
            triples = defaultdict(lambda: defaultdict(set))  # (subj_type, rel, obj_type) -> {entity_id: {connected_ids}}
            entity_type_mapping = defaultdict(set)  # entity_type -> {entity_ids}
            
            for tuple_item in tuples:
                # Extract information from tuple
                rel_id = tuple_item[0][1][0]
                start_label = tuple_item[0][1][1][0]
                rel_type = tuple_item[0][1][1][1]
                end_label = tuple_item[0][1][1][2]
                end_id = tuple_item[0][1][2]
                
                # Build relations dictionary (entity_type -> [(connected_type, relation)])
                if (end_label, rel_type) not in relations[start_label]:
                    relations[start_label].append((end_label, rel_type))
                
                # Build reverse relation as well
                if (start_label, rel_type) not in relations[end_label]:
                    relations[end_label].append((start_label, rel_type))
                
                # Build triples dictionary ((subj_type, rel, obj_type) -> {entity_id: {connected_ids}})
                triple_key = (start_label, rel_type, end_label)
                triples[triple_key][rel_id].add(end_id)
                
                # Build entity type mapping (entity_type -> {entity_ids})
                entity_type_mapping[start_label].add(rel_id)
                entity_type_mapping[end_label].add(end_id)
            
            # Convert defaultdict to regular dict and sets to lists for final output
            relations_dict = dict(relations)
            triples_dict = {}
            for key, value in triples.items():
                triples_dict[key] = dict(value)
            
            entity_type_dict = {}
            for entity_type, entity_ids in entity_type_mapping.items():
                entity_type_dict[entity_type] = sorted(list(entity_ids))
            
            return relations_dict, triples_dict, entity_type_dict


        def create_two_chain(tuples):
            """Create 2-chain tuples, filtering out those with underscores."""
            two_chain = []
            for i, j in enumerate(tuples):
                source_id = j[0][1][0]
                target_id = j[0][1][2]
                for m in tuples[i + 1:]:
                    source = m[0][1][0]
                    target = m[0][1][2]
                    if target_id == source and source_id != target:
                        # Check if any labels or relationship types contain underscores
                        j_labels_and_rel = [j[0][1][1][0], j[0][1][1][1], j[0][1][1][2]]
                        m_labels_and_rel = [m[0][1][1][0], m[0][1][1][1], m[0][1][1][2]]
                        
                        if any('_' in str(item) for item in j_labels_and_rel + m_labels_and_rel):
                            continue
                        
                        two_chain_tuple = (('2-chain', j[0][1], m[0][1], None, None))
                        two_chain.append(two_chain_tuple)
            
            return two_chain


        def create_two_inter(tuples):
            """Create 2-inter tuples, filtering out those with underscores."""
            two_inter = []
            for i, j in enumerate(tuples):
                source_id = j[0][1][0]
                target_id = j[0][1][2]
                for m in tuples[i + 1:]:
                    source = m[0][1][0]
                    target = m[0][1][2]
                    if source_id == source and target_id != target:
                        # Check if any labels or relationship types contain underscores
                        j_labels_and_rel = [j[0][1][1][0], j[0][1][1][1], j[0][1][1][2]]
                        m_labels_and_rel = [m[0][1][1][0], m[0][1][1][1], m[0][1][1][2]]
                        
                        if any('_' in str(item) for item in j_labels_and_rel + m_labels_and_rel):
                            continue
                        
                        two_inter_tuple = (('2-inter', j[0][1], m[0][1], None, None))
                        two_inter.append(two_inter_tuple)
            
            return two_inter


        def create_three_chain(tuples):
            """Create 3-chain tuples by finding chains of 3 connected relationships."""
            three_chain = []
            
            # First, create all 2-chains
            two_chains = []
            for i, j in enumerate(tuples):
                source_id = j[0][1][0]
                target_id = j[0][1][2]
                for m in tuples[i + 1:]:
                    source = m[0][1][0]
                    target = m[0][1][2]
                    if target_id == source and source_id != target:
                        # Check for underscores
                        j_labels_and_rel = [j[0][1][1][0], j[0][1][1][1], j[0][1][1][2]]
                        m_labels_and_rel = [m[0][1][1][0], m[0][1][1][1], m[0][1][1][2]]
                        
                        if not any('_' in str(item) for item in j_labels_and_rel + m_labels_and_rel):
                            two_chains.append((j[0][1], m[0][1]))
            
            # Now extend 2-chains to 3-chains
            for two_chain in two_chains:
                # The end of the 2-chain is two_chain[1][2]
                chain_end = two_chain[1][2]
                
                # Look for a third relationship that starts from chain_end
                for tuple_item in tuples:
                    third_start = tuple_item[0][1][0]
                    third_end = tuple_item[0][1][2]
                    
                    if chain_end == third_start and chain_end != third_end:
                        # Check for underscores in the third relationship
                        third_labels_and_rel = [tuple_item[0][1][1][0], tuple_item[0][1][1][1], tuple_item[0][1][1][2]]
                        
                        if not any('_' in str(item) for item in third_labels_and_rel):
                            # Ensure we don't create cycles
                            if third_end not in [two_chain[0][0], two_chain[1][0]]:
                                three_chain_tuple = (('3-chain', two_chain[0], two_chain[1], tuple_item[0][1], None))
                                three_chain.append(three_chain_tuple)
            
            return three_chain


        def create_three_inter(tuples):
            """Create 3-inter tuples by finding three relationships sharing a common starting node."""
            three_inter = []
            
            # Group tuples by their source node
            source_groups = {}
            for tuple_item in tuples:
                source_id = tuple_item[0][1][0]
                
                # Check for underscores
                labels_and_rel = [tuple_item[0][1][1][0], tuple_item[0][1][1][1], tuple_item[0][1][1][2]]
                if any('_' in str(item) for item in labels_and_rel):
                    continue
                    
                if source_id not in source_groups:
                    source_groups[source_id] = []
                source_groups[source_id].append(tuple_item[0][1])
            
            # Find groups with at least 3 relationships from the same source
            for source_id, relationships in source_groups.items():
                if len(relationships) >= 3:
                    # Generate all combinations of 3 relationships from this source
                    for combo in combinations(relationships, 3):
                        # Ensure all three have different targets
                        targets = [rel[2] for rel in combo]
                        if len(set(targets)) == 3:  # All targets are different
                            three_inter_tuple = (('3-inter', combo[0], combo[1], combo[2], None))
                            three_inter.append(three_inter_tuple)
            
            return three_inter


        def save_data_to_file(data_dict, output_path):
            """Save all data to a specified pickle file."""
            # Create the directory if it doesn't exist
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            with open(output_path, 'wb') as f:
                pickle.dump(data_dict, f)


        def main():
            """Main execution function."""
            parser = argparse.ArgumentParser()
            parser.add_argument('--input_json_file', type=str, required=True)
            parser.add_argument('--output_pkl_file', type=str, required=True)
            args = parser.parse_args()
            
            # Set random seed for reproducible splits
            random.seed(42)
            
            # Process the input file
            tuples = process_json_file(args.input_json_file)
            
            if not tuples:
                return 1
            
            # Apply negative sampling immediately after loading tuples
            entity_pools = build_entity_pools(tuples)
            tuples_with_negatives = add_negatives_to_tuples(tuples, entity_pools, num_negatives=1)
            
            # Generate all query structures using tuples with negatives
            two_chain_tuples = create_two_chain(tuples_with_negatives)
            two_inter_tuples = create_two_inter(tuples_with_negatives)
            three_chain_tuples = create_three_chain(tuples_with_negatives)
            three_inter_tuples = create_three_inter(tuples_with_negatives)
            
            # Add negatives to complex query structures
            two_chain_with_negs = add_negatives_to_complex_queries(two_chain_tuples, entity_pools, num_negatives=1)
            two_inter_with_negs = add_negatives_to_complex_queries(two_inter_tuples, entity_pools, num_negatives=1)
            three_chain_with_negs = add_negatives_to_complex_queries(three_chain_tuples, entity_pools, num_negatives=1)
            three_inter_with_negs = add_negatives_to_complex_queries(three_inter_tuples, entity_pools, num_negatives=1)
            
            # Create graph data structure
            relations, triples, entity_types = create_graph_data_structure(tuples)
            graph_data = [relations, triples, entity_types]
            
            # Create edge files from 1-chain (tuples already have negatives)
            # Convert 1-chain tuples to Query serialization format
            edges_serialized = convert_to_query_format(tuples_with_negatives)
            train_edges, val_edges, test_edges = split_data(edges_serialized)
            
            # Convert complex queries to Query serialization format
            two_chain_serialized = convert_complex_queries_to_query_format(two_chain_with_negs)
            two_inter_serialized = convert_complex_queries_to_query_format(two_inter_with_negs)
            three_chain_serialized = convert_complex_queries_to_query_format(three_chain_with_negs)
            three_inter_serialized = convert_complex_queries_to_query_format(three_inter_with_negs)
            
            # Combine 2-hop and 3-hop queries
            all_2hop_queries = two_chain_serialized + two_inter_serialized
            all_3hop_queries = three_chain_serialized + three_inter_serialized
            
            # Split query data
            train_queries_2, val_queries_2, test_queries_2 = split_data(all_2hop_queries)
            train_queries_3, val_queries_3, test_queries_3 = split_data(all_3hop_queries)
            
            # Create the comprehensive data dictionary
            all_data = {
                'graph': graph_data,
                'train_edges': train_edges,
                'val_edges': val_edges,
                'test_edges': test_edges,
                'train_queries_2': train_queries_2,
                'val_queries_2': val_queries_2,
                'test_queries_2': test_queries_2,
                'train_queries_3': train_queries_3,
                'val_queries_3': val_queries_3,
                'test_queries_3': test_queries_3
            }
            
            # Save all data to the specified output file
            save_data_to_file(all_data, args.output_pkl_file)
            print(f"Successfully processed {len(tuples)} tuples and saved to {args.output_pkl_file}")
            
            return 0


        if __name__ == "__main__":
            exit(main())
    args:
      - --input_json_file
      - { inputValue: input_json_file }
      - --output_pkl_file
      - { outputPath: output_pkl_file }